import numpy as np
import matplotlib.pyplot as plt

# Parameters
N_bits = 12                # ADC bits
Vpp_adc = 1.2              # ADC full range peak-to-peak (V)
Vrms_signal = 0.2          # Input signal RMS (V)
fs = 100000                # Sampling frequency (Hz)
f_signal = 1000            # Signal frequency (Hz)
t_duration = 0.01          # Duration (s)
noise_std_dev_b = 0.5      # Noise standard deviation for part b (V)
noise_pp_c = 1.0           # Noise peak-to-peak for part c (V)

# Create time array
t = np.linspace(0, t_duration, int(fs * t_duration), endpoint=False)

# Signal peak amplitude
signal_peak = Vrms_signal * np.sqrt(2)
signal_pp = 2 * signal_peak

# Part a: Calculate SNR for ideal ADC
# Theoretical SNR for full-scale input
SNR_theoretical = 6.02 * N_bits + 1.76
# Adjust for input signal not using full range
signal_range_ratio = signal_pp / Vpp_adc
SNR_adjusted = SNR_theoretical + 20 * np.log10(signal_range_ratio)

# Create sinusoidal signal
signal = signal_peak * np.sin(2 * np.pi * f_signal * t)

# Calculate LSB size
LSB = Vpp_adc / (2**N_bits)

# Simulate ADC quantization
def quantize(signal, LSB, Vpp_adc):
    # Clip to ADC range
    clipped = np.clip(signal, -Vpp_adc/2, Vpp_adc/2)
    # Quantize
    return np.round(clipped / LSB) * LSB

# Part a: Ideal ADC
signal_quantized_a = quantize(signal, LSB, Vpp_adc)
quant_noise_a = signal_quantized_a - signal
quant_noise_power_a = np.mean(quant_noise_a**2)
signal_power = np.mean(signal**2)
SNR_simulated_a = 10 * np.log10(signal_power / quant_noise_power_a)

# Part b: Signal with Gaussian noise
noise_b = np.random.normal(0, noise_std_dev_b, len(t))
signal_with_noise_b = signal + noise_b
signal_quantized_b = quantize(signal_with_noise_b, LSB, Vpp_adc)
noise_power_b = np.mean(noise_b**2)
input_SNR_b = 10 * np.log10(signal_power / noise_power_b)
output_noise_b = signal_quantized_b - signal
output_noise_power_b = np.mean(output_noise_b**2)
output_SNR_b = 10 * np.log10(signal_power / output_noise_power_b)

# Part c: Signal with uniform noise
noise_c = np.random.uniform(-noise_pp_c/2, noise_pp_c/2, len(t))
signal_with_noise_c = signal + noise_c
signal_quantized_c = quantize(signal_with_noise_c, LSB, Vpp_adc)
noise_power_c = np.mean(noise_c**2)
input_SNR_c = 10 * np.log10(signal_power / noise_power_c)
output_noise_c = signal_quantized_c - signal
output_noise_power_c = np.mean(output_noise_c**2)
output_SNR_c = 10 * np.log10(signal_power / output_noise_power_c)

# Create plots
plt.figure(figsize=(15, 10))

# Plot 1: Original signal vs Quantized signal (Part a)
plt.subplot(3, 2, 1)
plt.plot(t[:100], signal[:100], label='Original Signal')
plt.plot(t[:100], signal_quantized_a[:100], label='Quantized Signal')
plt.title('Part a: Original vs Quantized Signal')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude (V)')
plt.legend()
plt.grid(True)

# Plot 2: Quantization noise (Part a)
plt.subplot(3, 2, 2)
plt.plot(t[:100], quant_noise_a[:100])
plt.title(f'Part a: Quantization Noise (SNR = {SNR_simulated_a:.2f} dB)')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude (V)')
plt.grid(True)

# Plot 3: Signal with Gaussian noise (Part b)
plt.subplot(3, 2, 3)
plt.plot(t[:100], signal[:100], label='Original Signal')
plt.plot(t[:100], signal_with_noise_b[:100], label='Signal + Gaussian Noise')
plt.plot(t[:100], signal_quantized_b[:100], label='Quantized Signal')
plt.title(f'Part b: Signal with Gaussian Noise (Input SNR = {input_SNR_b:.2f} dB)')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude (V)')
plt.legend()
plt.grid(True)

# Plot 4: Output noise (Part b)
plt.subplot(3, 2, 4)
plt.plot(t[:100], output_noise_b[:100])
plt.title(f'Part b: Output Noise (Output SNR = {output_SNR_b:.2f} dB)')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude (V)')
plt.grid(True)

# Plot 5: Signal with uniform noise (Part c)
plt.subplot(3, 2, 5)
plt.plot(t[:100], signal[:100], label='Original Signal')
plt.plot(t[:100], signal_with_noise_c[:100], label='Signal + Uniform Noise')
plt.plot(t[:100], signal_quantized_c[:100], label='Quantized Signal')
plt.title(f'Part c: Signal with Uniform Noise (Input SNR = {input_SNR_c:.2f} dB)')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude (V)')
plt.legend()
plt.grid(True)

# Plot 6: Output noise (Part c)
plt.subplot(3, 2, 6)
plt.plot(t[:100], output_noise_c[:100])
plt.title(f'Part c: Output Noise (Output SNR = {output_SNR_c:.2f} dB)')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude (V)')
plt.grid(True)

plt.tight_layout()

# Print results
print(f"Part a - Ideal ADC:")
print(f"Theoretical SNR (full scale) = {SNR_theoretical:.2f} dB")
print(f"Adjusted SNR (for {signal_pp:.4f}V pp input in {Vpp_adc}V ADC) = {SNR_adjusted:.2f} dB")
print(f"Simulated SNR = {SNR_simulated_a:.2f} dB")

print(f"\nPart b - Input signal with Gaussian noise:")
print(f"Input SNR = {input_SNR_b:.2f} dB")
print(f"Output SNR = {output_SNR_b:.2f} dB")

print(f"\nPart c - Input signal with uniform noise:")
print(f"Input SNR = {input_SNR_c:.2f} dB")
print(f"Output SNR = {output_SNR_c:.2f} dB")

# Show plots
plt.savefig("adc_snr_plots.png")
plt.show()
